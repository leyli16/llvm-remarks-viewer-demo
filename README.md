
# LLVM Remarks Viewer Demo

A Lightweight demo that **parses and visualizes LLVM optimization remarks** (`.opt.yaml` files) generated by Clang. With it you can quickly understand what optimizations were applied - or missed - and why.

---

## Example C++ Code

The following simple C++ program is used to generate LLVM remarks for this demo:

```cpp
int square(int x) {
    return x * x;
}

int main() {
    int a = square(5);
    return 0;
}
```

Compile it using:

```bash
clang++ -fsave-optimization-record=yaml example.cpp -o example
```

This will produce `example.opt.yaml`, which you can then parse and visualize.

---


## Demo Preview

### Frontend UI Screenshot

This project also includes a custom frontend demo that renders remarks as charts and a summary table:

![LLVM Remarks Viewer Screenshot](images/screenshot.png)

---

### Tested with LLVM’s opt-viewer

As a reference, I tested the official `opt-viewer` tool to understand its capabilities and limitations.

####  Screenshot: opt-viewer Output

Here is the result of running `opt-viewer.py` on the same LLVM `.opt.yaml` remark file:

| Index Page | Source View |
|------------|-------------|
| ![opt-viewer Index Screenshot](images/opt-viewer-index.png) | ![opt-viewer Source Screenshot](images/opt-viewer-source.png) |

This tool displays remarks in a tabular format with clickable source references and highlights inlined optimizations.  
While very useful for source-level inspection, it doesn't provide aggregated views like charts or summaries.

---

## Remarks Visualization Flow

This diagram shows how the pieces connect:

![LLVM Remarks Flow](images/llvm_remarks_flow_updated.png)

---

## How It Works (Usage Guide)

### 1. Generate LLVM Optimization Remarks (YAML)

Compile your C++ file using Clang with optimization remark output enabled:

```bash
clang++ -fsave-optimization-record=yaml example.cpp -o example
```

This will generate `example.opt.yaml`.

### 2. Convert YAML to JSON

Run the Python parser to extract structured data:

```bash
python3 parse_remarks.py
```

This will output `remarks.json`.

### 3. Launch the Frontend UI

Start a local server and view the HTML frontend:

```bash
python -m http.server
```

Then visit `http://localhost:8000/index.html` in your browser to see the visualized data.

---

## Project Structure

```
llvm-remarks-viewer-demo/
├── example.cpp                  # Sample C++ source code
├── example.opt.yaml             # Optimization remarks generated by Clang
├── parse_remarks.py             # Python script to parse .opt.yaml
├── remarks.json                 # Output JSON used by frontend
├── demo_remarks.json            # Static sample file for demo UI
├── index.html                   # HTML+JS frontend for visualization
└── README.md                    # Project documentation
```

---


## Why These Fields Are Visualized

LLVM’s `.opt.yaml` files include many low-level remarks. This tool extracts only the most relevant, actionable fields to help developers quickly interpret compiler decisions:

| Field              | Reason for Visualization                                                                 |
|--------------------|-------------------------------------------------------------------------------------------|
| `Function`         | Identifies which function the remark applies to                                          |
| `Pass` / `Name`    | Shows which compiler pass emitted the remark and what type it is                         |
| `StackSize`        | Key for understanding stack usage in offload/accelerated contexts                        |
| `InstructionCount` | Useful for estimating function complexity and potential inlining                         |
| `DebugLoc`         | Enables mapping remarks to source lines                                                  |

---

## JSON Output Format

The `remarks.json` file contains simplified entries ready for UI rendering.  
See `demo_remarks.json` as a reference.

Each entry includes:

| Field     | Description                                                                 |
|-----------|-----------------------------------------------------------------------------|
| `Pass`    | LLVM pass that generated the remark (e.g., `asm-printer`)                  |
| `Name`    | Type of remark (e.g., `StackSize`, `InstructionCount`)                    |
| `Function`| Name of the function being remarked on                                     |
| `Message` | Human-readable description of the remark                                   |
| `File`    | Source file where the remark originated (if available)                    |
| `Line`    | Line number in the source file (if available)                             |

---

## Future Plans

Based on the opt-viewer comparison and aligned with the GSoC project goals, the following features are planned:

- Add visualizations for hotness, remark frequency, or top impacted functions  
- Highlight source-level locations similar to opt-viewer  
- Add filters and sorting by pass, function, or remark type  
- Support multiple input files and aggregate data across files or projects  
- Integrate LLMs to explain common remarks or suggest optimizations  
- Provide a CLI tool or compiler wrapper for easier remark generation and analysis  


---

## License

This project is licensed under the MIT License.

---

## Author

Created by [Le Li](https://github.com/leyli16) as part of a GSoC demo for the LLVM project.
