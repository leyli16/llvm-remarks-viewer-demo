# LLVM Remarks Viewer Demo

This is a lightweight demo that **parses and visualizes LLVM optimization remarks** (`.opt.yaml` files) generated by Clang, helping developers understand what optimizations were appliedâ€”or missedâ€”and why.

---

## ğŸ”„ LLVM Remarks Visualization Flow

The diagram below shows the full process from compiling a C++ source file with Clang, to generating `.opt.yaml`, parsing it with Python, optionally outputting JSON, and displaying the result in a browser.

![LLVM Remarks Flow](llvm_remarks_flow_updated.png)

---

## ğŸ›  How It Works

1. **Compile a C++ file with optimization remarks enabled:**
   ```bash
   clang++ -fsave-optimization-record=yaml example.cpp -o example
   ```

   This will generate a file named `example.opt.yaml` in the current directory.

2. **Run the Python parser:**
   ```bash
   python3 parse_remarks.py
   ```

   This reads the `.opt.yaml` file and optionally outputs a simplified `.json` file.

3. **View with the HTML page:**
   Start a local server:
   ```bash
   python3 -m http.server 8000
   ```
   Then open `http://localhost:8000/index.html` in your browser.

---

## ğŸ“ Project Structure

```
llvm-remarks-viewer-demo/
â”œâ”€â”€ example.cpp                  # Sample C++ source code
â”œâ”€â”€ example.opt.yaml             # Optimization remarks generated by Clang
â”œâ”€â”€ parse_remarks.py             # Python script to parse .opt.yaml
â”œâ”€â”€ remarks.json                 # JSON version for frontend use
â”œâ”€â”€ index.html                   # Simple HTML/JS front-end
â”œâ”€â”€ llvm_remarks_flow_updated.png # Updated architecture diagram
â””â”€â”€ README.md                    # This file
```

---

## ğŸ¯ Why We Select and Visualize Specific Fields

LLVMâ€™s `.opt.yaml` files often contain a large number of low-level remarksâ€”some deeply tied to internal compiler behavior or platform-specific debugging. These remarks are often too granular or noisy to be helpful for most developers.

To simplify visualization and maximize insight, this tool filters and extracts only the most **actionable, human-relevant** fields. These include key metrics like **function stack size, instruction count**, and **optimization passes**.

### âœ… Visualized Fields and Why

| Field              | Reason for Visualization                                                                 |
|--------------------|-------------------------------------------------------------------------------------------|
| `Function`         | Shows which function the remark is associated with, useful for grouping and context      |
| `Pass` / `Name`    | Identifies which optimization pass issued the remark and its type (e.g., StackSize)      |
| `StackSize`        | Important for estimating memory usage, especially for accelerator/offload scenarios      |
| `InstructionCount` | Helps evaluate function complexity and optimization impact                               |
| `DebugLoc`         | (Optional) Shows source file and line number for traceability                            |

---

## ğŸ§¾ Explanation of JSON Fields

The `remarks.json` file contains simplified, structured data extracted from the original `.opt.yaml`. This data serves as the input for the frontend visualization.

> ğŸ’¡ For reference, see `demo_remarks.json` in the repository â€” it is a static example used to demonstrate how the UI renders parsed remarks.

| Field       | Description                                                                 |
|-------------|-----------------------------------------------------------------------------|
| `Pass`      | The name of the LLVM optimization pass that generated this remark           |
| `Name`      | The type of remark, e.g., `InstructionCount`, `StackSize`, `Missed`         |
| `Function`  | The (possibly mangled) name of the function where the remark occurred       |
| `Message`   | A human-readable summary explaining the remark                              |
| `File`      | The source file in which the remark was triggered                           |
| `Line`      | The line number in the source file where the remark occurred                |

---

## ğŸš€ Future Plans

- Add filtering/grouping by optimization pass
- Highlight source location (file + line)
- Display summary statistics (counts, common passes)
- Explore LLM integration for explaining remarks

---

## ğŸ“œ License

This project uses the MIT License.

---

## ğŸ™‹â€â™€ï¸ Author

Created by [Le Li](https://github.com/leyli16) as part of a GSoC demo for the LLVM project.
